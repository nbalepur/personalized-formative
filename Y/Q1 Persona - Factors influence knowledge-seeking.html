<head>    <style>.highlight-buttercream { background-color: #ffe066; padding: 2px 4px; border-radius: 4px; } .highlight-apricot { background-color: #ff9966; padding: 2px 4px; border-radius: 4px; } .highlight-mistgreen { background-color: #6fdcbf; padding: 2px 4px; border-radius: 4px; } .highlight-lavender { background-color: #d3a4f9; padding: 2px 4px; border-radius: 4px; } .highlight-powderblue { background-color: #9ecbfa; padding: 2px 4px; border-radius: 4px; }      body {        font-family: "Segoe UI", "Helvetica Neue", sans-serif;        background: #ffffff;        color: #06262d;        margin: 40px auto;        max-width: 70%;        line-height: 1.65;        font-size: 16px;      }        h2, h3 {        border-bottom: 2px solid #e0e0e0;        padding-bottom: 6px;        margin-top: 40px;        color: #06262d;      }        ul {        background: #f5eee6;        border-left: 4px solid #34b88e;        padding: 10px 20px;        margin-bottom: 20px;        list-style-type: none;      }        li::marker {        color: #ed5298;      }        b {        color: #ed5298;      }        p {        margin-bottom: 20px;      }        sub {        vertical-align: sub;        font-size: smaller;      }        ol {        font-size: 0.95em;        padding-left: 20px;      }        ol li {        margin-bottom: 6px;      }        a {        color: #2980b9;        text-decoration: none;      }        a:hover {        text-decoration: underline;      }    </style>  </head><b>Query:</b> What factors influence employees' knowledge-seeking behavior when using generative AI tools in the workplace?
<br /><b>Requirements:</b>
<ol><li> I can try to focus my search on papers that go beyond standard technology acceptance models (like TAM or UTAUT), which might help you discover factors unique to generative AI.
<li> 
<li> I can add a forward-looking section with future research questions and practical implications for managers, which might help you develop ideas for your paper’s discussion and conclusion.
<li> 
<li> 
<li> I can present the influencing factors using a structured, definitions-first approach within a conceptual framework, which might help you by mirroring your style of building organized conceptualizations.
<li> 
<li> 
<li> </ol> <br />To best address your query, this response will <mark>focus on factors beyond standard models</mark>, present information using a <mark>structured, definitions-first approach</mark>, and conclude with a <mark>dedicated section on future research and managerial implications</mark> to help guide your work.

<h2>Section 1: Core Technology Acceptance and Contextual Factors</h2>
<ul> <li> <b>TL;DR:</b> Employees' decisions to use generative AI for knowledge seeking are influenced by traditional factors like how useful and easy the tool is to use. However, a more critical factor is compatibility, or how well the AI tool integrates with their existing daily tasks and workflows. </ul>
<p>Several established models, such as the Technology Acceptance Model (TAM) and the Unified Theory of Acceptance and Use of Technology (UTAUT), provide a foundation for understanding employee adoption of generative AI [<a href="#ref-5">5</a>, <a href="#ref-8">8</a>, <a href="#ref-16">16</a>]. These models identify several core factors that consistently influence an employee's intention to use a new technology. <mark>These factors include</mark>:
<ul>
<li><b>Performance Expectancy</b>: The belief that using the AI tool will enhance job performance. This is a primary driver, as employees are more likely to adopt tools they perceive as beneficial to their work [<a href="#ref-1">1</a>, <a href="#ref-17">17</a>, <a href="#ref-18">18</a>].</li>
<li><b>Effort Expectancy</b>: The perceived ease of use of the AI tool. When AI systems are user-friendly and intuitive, employees are more likely to use them regularly and experience greater benefits [<a href="#ref-1">1</a>, <a href="#ref-2">2</a>, <a href="#ref-18">18</a>].</li>
<li><b>Facilitating Conditions</b>: The availability of organizational and technical resources to support the use of the technology. Employees are more likely to experiment with AI when they have the necessary infrastructure, training, and support from management [<a href="#ref-11">11</a>, <a href="#ref-13">13</a>, <a href="#ref-17">17</a>].</li>
</ul>
</p>
<p>While foundational, these factors do not operate in isolation and are heavily influenced by the work context. The most significant contextual driver is <b>compatibility</b>, which refers to how well a generative AI tool fits into an employee's existing workflows and practices [<a href="#ref-3">3</a>]. When a tool integrates seamlessly—for example, by automating coding tasks or improving debugging efficiency for a software engineer—it is viewed as highly compatible and is more likely to be adopted. Conversely, if a tool disrupts established procedures, it may face resistance [<a href="#ref-3">3</a>]. The role of <b>social influence</b>—the degree to which an individual perceives that important others believe they should use the new system—presents a more complex picture. Some studies find it is a significant driver of adoption, particularly through support from supervisors and peers [<a href="#ref-2">2</a>, <a href="#ref-17">17</a>, <a href="#ref-18">18</a>]. However, other research in specific contexts, like software engineering, found that social factors did not significantly impact the intention to use these tools, suggesting its influence can be nuanced [<a href="#ref-3">3</a>, <a href="#ref-14">14</a>].</p>

<h2>Section 2: Individual and Psychological Drivers of Knowledge Seeking</h2>
<ul> <li> <b>TL;DR:</b> Beyond the tool's features, an employee's internal characteristics and psychological reactions are crucial. Personal traits like proactivity and confidence, cognitive abilities to apply AI-generated knowledge, and psychological responses like trust and ethical concerns heavily influence their knowledge-seeking behavior. </ul>
<p><mark>An employee’s individual disposition and cognitive approach</mark> play a pivotal role in their engagement with generative AI tools. Key factors include:
<ul>
<li><b>Knowledge Application</b>: This is the ability to not just acquire information from an AI tool but to effectively utilize that knowledge in relevant work tasks. The successful application of AI-generated knowledge enhances an employee's performance and their frequency of using the tool [<a href="#ref-1">1</a>, <a href="#ref-4">4</a>].</li>
<li><b>Self-Efficacy and Personal Innovativeness</b>: Self-efficacy is an employee’s confidence in their ability to learn and use AI technologies effectively. Higher self-efficacy leads to better outcomes and more frequent use [<a href="#ref-1">1</a>, <a href="#ref-11">11</a>]. This is related to personal innovativeness, or an individual's willingness to experiment with new technologies, which positively shapes their perceptions of AI tools [<a href="#ref-3">3</a>].</li>
<li><b>Proactive Personality and Motivation</b>: Individuals with a proactive personality are more likely to take the initiative to explore new technologies like generative AI. They actively identify potential benefits, which boosts their perception of the tool's usefulness and ease of use, leading to greater acceptance [<a href="#ref-12">12</a>].</li>
</ul>
</p>
<p>Psychological perceptions also strongly mediate an employee's willingness to seek knowledge from AI. <b>Trust in technology</b> is a critical antecedent for continued use; employees must trust the AI's output and processes to rely on it [<a href="#ref-11">11</a>, <a href="#ref-14">14</a>, <a href="#ref-15">15</a>]. This is closely linked to addressing <b>security and privacy</b> issues, which are fundamental prerequisites for employee adoption [<a href="#ref-13">13</a>, <a href="#ref-17">17</a>]. Furthermore, an employee's <b>ethical considerations</b> regarding GenAI can impact their satisfaction and continuous usage, highlighting the need for responsible implementation [<a href="#ref-13">13</a>]. On the other hand, some employees may exhibit <b>AI aversion</b>, a negative perception that can hinder adoption even if the tool is proven to be effective. Addressing this aversion by building knowledge and understanding of the AI's capabilities is crucial for widespread use [<a href="#ref-18">18</a>].</p>

<h2><mark>Section 3: Future Research and Managerial Implications</mark></h2>
<ul> <li> <b>TL;DR:</b> Future studies should adopt more dynamic, long-term methods to understand AI adoption across various industries. For managers, successful integration requires focusing on seamless workflow compatibility, providing comprehensive support and training, and proactively building employee trust to mitigate fears about AI. </ul>
<p><mark>To deepen the understanding of how employees engage with generative AI for knowledge-seeking</mark>, future research should move beyond static, cross-sectional studies. Researchers call for longitudinal studies to validate findings and understand the dynamic evolution of AI adoption over time [<a href="#ref-1">1</a>, <a href="#ref-9">9</a>]. There is also a need to expand research to more diverse organizational contexts and industries (e.g., manufacturing vs. services) to improve the generalizability of findings [<a href="#ref-9">9</a>]. Moreover, scholars suggest exploring additional theoretical perspectives beyond common technology acceptance models to capture the full complexity of human-AI interaction [<a href="#ref-3">3</a>, <a href="#ref-9">9</a>]. A specific challenge for future work is to determine how to effectively ensemble or aggregate the qualitative, creative outputs from generative AI with human-generated content, which is far more complex than combining quantitative data [<a href="#ref-10">10</a>].</p>
<p>For managers and organizational leaders, the research offers several practical implications for fostering effective knowledge-seeking with generative AI. First, organizations should prioritize compatibility by selecting and implementing tools that integrate smoothly into existing employee workflows, as this is a core driver of adoption [<a href="#ref-3">3</a>]. Second, providing robust <b>facilitating conditions</b> is essential; this includes offering the necessary technical infrastructure, resources, and continuous training to build employee skills and confidence [<a href="#ref-1">1</a>, <a href="#ref-13">13</a>, <a href="#ref-18">18</a>]. Such support can also help reduce AI aversion by demystifying the technology [<a href="#ref-18">18</a>]. Finally, leaders must actively build a culture of trust by addressing employees' ethical, security, and privacy concerns and ensuring that AI is deployed responsibly [<a href="#ref-13">13</a>, <a href="#ref-15">15</a>]. Encouraging senior management to use these tools can also create positive social influence, promoting wider adoption throughout the organization [<a href="#ref-18">18</a>].</p>

<h3>References</h3>
<ol><li id="ref-1">AI-Powered E-Learning for Lifelong Learners: Impact on Performance and Knowledge Application (Ahn et. al., 2024)</li>
<li id="ref-2">Determinants of Generative AI System Adoption and Usage Behavior in Korean Companies: Applying the UTAUT Model (Kim et. al., 2024)</li>
<li id="ref-3">Navigating the Complexity of Generative AI Adoption in Software Engineering (Russo et. al., 2023)</li>
<li id="ref-4">Effects of ChatGPT’s AI capabilities and human-like traits on spreading information in work environments (Jo et. al., 2024)</li>
<li id="ref-5">LLM-Based Interaction for Content Generation: A Case Study on the Perception of Employees in an IT Department (Agossah et. al., 2023)</li>
<li id="ref-6">Artificial intelligence, workers, and future of work skills. (Bankins et. al., 2024)</li>
<li id="ref-7">Generative artificial intelligence as a new context for management theories: analysis of ChatGPT (Korzyński et. al., 2023)</li>
<li id="ref-8">Impact of Motivation Factors for Using Generative AI Services on Continuous Use Intention: Mediating Trust and Acceptance Attitude (Kang et. al., 2024)</li>
<li id="ref-9">How and when artificial intelligence adoption promotes employee knowledge sharing? The role of paradoxical leadership and technophilia (Hu et. al., 2025)</li>
<li id="ref-10">Human-AI Ensembles: When Can They Work? (Choudhary et. al., 2023)</li>
<li id="ref-11">Exploring User Behavioral Intentions and Their Relationship With AI Design Tools: A Future Outlook on Intelligent Design (Ma et. al., 2024)</li>
<li id="ref-12">The Impact of Proactive Personality on Career Decision-Making Self-Efficacy: The Role of AI Acceptance and Innovation Skills (Li et. al., 2025)</li>
<li id="ref-13">Factors influencing academic staff satisfaction and continuous usage of generative artificial intelligence (GenAI) in higher education (Baig et. al., 2025)</li>
<li id="ref-14">Acceptance of Generative AI in the Creative Industry: Examining the role of Brand Recognition and Trust in the AI adoption (Weglarz et. al., 2025)</li>
<li id="ref-15">Generative AI as a catalyst for HRM practices: mediating effects of trust (kumarRaja et. al., 2024)</li>
<li id="ref-16">Do Comments and Expertise Still Matter? An Experiment on Programmers' Adoption of AI-Generated JavaScript Code (Li et. al., 2025)</li>
<li id="ref-17">The Impact of AI on Organizational Employees: A Literature Review (Wang et. al., 2023)</li>
<li id="ref-18">Adoption of AI-Enabled Tools in Social Development Organizations in India: An Extension of UTAUT Model (Jain et. al., 2022)</li>
<li id="ref-19">The Impact of AI Usage on University Students’ Willingness for Autonomous Learning (Wang et. al., 2024)</li>
<li id="ref-20">The Role of Artificial Intelligence in Promoting Employee Workplace Green Behaviors: A Systematic Analysis (Olazo et. al., 2025)</li></ol>
