<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta http-equiv="Content-Style-Type" content="text/css">
  <title></title>
  <meta name="Generator" content="Cocoa HTML Writer">
  <meta name="CocoaVersion" content="2575.2">
  <style type="text/css">
    p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Menlo; color: #8cd3fe; -webkit-text-stroke: #8cd3fe; background-color: #181818}
    p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Menlo; color: #c1c1c1; -webkit-text-stroke: #c1c1c1}
    p.p3 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Menlo; color: #c1c1c1; -webkit-text-stroke: #c1c1c1; min-height: 14.0px}
    p.p4 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Menlo; color: #c1c1c1; -webkit-text-stroke: #c1c1c1; background-color: #181818}
    span.s1 {font-kerning: none; color: #6d6d6d; -webkit-text-stroke: 0px #6d6d6d}
    span.s2 {font-kerning: none; color: #4689cc; -webkit-text-stroke: 0px #4689cc}
    span.s3 {font-kerning: none; color: #c1c1c1; -webkit-text-stroke: 0px #c1c1c1}
    span.s4 {font-kerning: none; color: #cdad6a; -webkit-text-stroke: 0px #cdad6a}
    span.s5 {font-kerning: none; color: #cacaca; -webkit-text-stroke: 0px #cacaca}
    span.s6 {font-kerning: none}
    span.s7 {font-kerning: none; color: #c27e65; -webkit-text-stroke: 0px #c27e65}
    span.s8 {font-kerning: none; color: #a7c598; -webkit-text-stroke: 0px #a7c598}
    span.s9 {font-kerning: none; color: #6d6d6d; background-color: #181818; -webkit-text-stroke: 0px #6d6d6d}
    span.s10 {font-kerning: none; color: #4689cc; background-color: #181818; -webkit-text-stroke: 0px #4689cc}
    span.s11 {font-kerning: none; background-color: #181818}
    span.s12 {font-kerning: none; color: #8cd3fe; background-color: #181818; -webkit-text-stroke: 0px #8cd3fe}
    span.s13 {font-kerning: none; color: #c27e65; background-color: #181818; -webkit-text-stroke: 0px #c27e65}
    span.s14 {font-kerning: none; color: #8cd3fe; -webkit-text-stroke: 0px #8cd3fe}
  </style>
</head>
<body>
<p class="p1"><span class="s1">&lt;</span><span class="s2">head</span><span class="s1">&gt;</span><span class="s3"><span class="Apple-converted-space">    </span></span><span class="s1">&lt;</span><span class="s2">style</span><span class="s1">&gt;</span><span class="s4">.highlight-buttercream</span><span class="s5"> { </span><span class="s6">background-color</span><span class="s5">: </span><span class="s7">#ffe066</span><span class="s5">; </span><span class="s6">padding</span><span class="s5">: </span><span class="s8">2px</span><span class="s5"> </span><span class="s8">4px</span><span class="s5">; </span><span class="s6">border-radius</span><span class="s5">: </span><span class="s8">4px</span><span class="s5">; } </span><span class="s4">.highlight-apricot</span><span class="s5"> { </span><span class="s6">background-color</span><span class="s5">: </span><span class="s7">#ff9966</span><span class="s5">; </span><span class="s6">padding</span><span class="s5">: </span><span class="s8">2px</span><span class="s5"> </span><span class="s8">4px</span><span class="s5">; </span><span class="s6">border-radius</span><span class="s5">: </span><span class="s8">4px</span><span class="s5">; } </span><span class="s4">.highlight-mistgreen</span><span class="s5"> { </span><span class="s6">background-color</span><span class="s5">: </span><span class="s7">#6fdcbf</span><span class="s5">; </span><span class="s6">padding</span><span class="s5">: </span><span class="s8">2px</span><span class="s5"> </span><span class="s8">4px</span><span class="s5">; </span><span class="s6">border-radius</span><span class="s5">: </span><span class="s8">4px</span><span class="s5">; } </span><span class="s4">.highlight-lavender</span><span class="s5"> { </span><span class="s6">background-color</span><span class="s5">: </span><span class="s7">#d3a4f9</span><span class="s5">; </span><span class="s6">padding</span><span class="s5">: </span><span class="s8">2px</span><span class="s5"> </span><span class="s8">4px</span><span class="s5">; </span><span class="s6">border-radius</span><span class="s5">: </span><span class="s8">4px</span><span class="s5">; } </span><span class="s4">.highlight-powderblue</span><span class="s5"> { </span><span class="s6">background-color</span><span class="s5">: </span><span class="s7">#9ecbfa</span><span class="s5">; </span><span class="s6">padding</span><span class="s5">: </span><span class="s8">2px</span><span class="s5"> </span><span class="s8">4px</span><span class="s5">; </span><span class="s6">border-radius</span><span class="s5">: </span><span class="s8">4px</span><span class="s5">; }<span class="Apple-converted-space">      </span></span><span class="s4">body</span><span class="s5"> {<span class="Apple-converted-space">        </span></span><span class="s6">font-family</span><span class="s5">: </span><span class="s7">"Segoe UI"</span><span class="s5">, </span><span class="s7">"Helvetica Neue"</span><span class="s5">, </span><span class="s7">sans-serif</span><span class="s5">;<span class="Apple-converted-space">        </span></span><span class="s6">background</span><span class="s5">: </span><span class="s7">#ffffff</span><span class="s5">;<span class="Apple-converted-space">        </span></span><span class="s6">color</span><span class="s5">: </span><span class="s7">#06262d</span><span class="s5">;<span class="Apple-converted-space">        </span></span><span class="s6">margin</span><span class="s5">: </span><span class="s8">40px</span><span class="s5"> </span><span class="s7">auto</span><span class="s5">;<span class="Apple-converted-space">        </span></span><span class="s6">max-width</span><span class="s5">: </span><span class="s8">70%</span><span class="s5">;<span class="Apple-converted-space">        </span></span><span class="s6">line-height</span><span class="s5">: </span><span class="s8">1.65</span><span class="s5">;<span class="Apple-converted-space">        </span></span><span class="s6">font-size</span><span class="s5">: </span><span class="s8">16px</span><span class="s5">;<span class="Apple-converted-space">      </span>}<span class="Apple-converted-space">        </span></span><span class="s4">h2</span><span class="s5">, </span><span class="s4">h3</span><span class="s5"> {<span class="Apple-converted-space">        </span></span><span class="s6">border-bottom</span><span class="s5">: </span><span class="s8">2px</span><span class="s5"> </span><span class="s7">solid</span><span class="s5"> </span><span class="s7">#e0e0e0</span><span class="s5">;<span class="Apple-converted-space">        </span></span><span class="s6">padding-bottom</span><span class="s5">: </span><span class="s8">6px</span><span class="s5">;<span class="Apple-converted-space">        </span></span><span class="s6">margin-top</span><span class="s5">: </span><span class="s8">40px</span><span class="s5">;<span class="Apple-converted-space">        </span></span><span class="s6">color</span><span class="s5">: </span><span class="s7">#06262d</span><span class="s5">;<span class="Apple-converted-space">      </span>}<span class="Apple-converted-space">        </span></span><span class="s4">ul</span><span class="s5"> {<span class="Apple-converted-space">        </span></span><span class="s6">background</span><span class="s5">: </span><span class="s7">#f5eee6</span><span class="s5">;<span class="Apple-converted-space">        </span></span><span class="s6">border-left</span><span class="s5">: </span><span class="s8">4px</span><span class="s5"> </span><span class="s7">solid</span><span class="s5"> </span><span class="s7">#34b88e</span><span class="s5">;<span class="Apple-converted-space">        </span></span><span class="s6">padding</span><span class="s5">: </span><span class="s8">10px</span><span class="s5"> </span><span class="s8">20px</span><span class="s5">;<span class="Apple-converted-space">        </span></span><span class="s6">margin-bottom</span><span class="s5">: </span><span class="s8">20px</span><span class="s5">;<span class="Apple-converted-space">        </span></span><span class="s6">list-style-type</span><span class="s5">: </span><span class="s7">none</span><span class="s5">;<span class="Apple-converted-space">      </span>}<span class="Apple-converted-space">        </span></span><span class="s4">li::marker</span><span class="s5"> {<span class="Apple-converted-space">        </span></span><span class="s6">color</span><span class="s5">: </span><span class="s7">#ed5298</span><span class="s5">;<span class="Apple-converted-space">      </span>}<span class="Apple-converted-space">        </span></span><span class="s4">b</span><span class="s5"> {<span class="Apple-converted-space">        </span></span><span class="s6">color</span><span class="s5">: </span><span class="s7">#ed5298</span><span class="s5">;<span class="Apple-converted-space">      </span>}<span class="Apple-converted-space">        </span></span><span class="s4">p</span><span class="s5"> {<span class="Apple-converted-space">        </span></span><span class="s6">margin-bottom</span><span class="s5">: </span><span class="s8">20px</span><span class="s5">;<span class="Apple-converted-space">      </span>}<span class="Apple-converted-space">        </span></span><span class="s4">sub</span><span class="s5"> {<span class="Apple-converted-space">        </span></span><span class="s6">vertical-align</span><span class="s5">: </span><span class="s7">sub</span><span class="s5">;<span class="Apple-converted-space">        </span></span><span class="s6">font-size</span><span class="s5">: </span><span class="s7">smaller</span><span class="s5">;<span class="Apple-converted-space">      </span>}<span class="Apple-converted-space">        </span></span><span class="s4">ol</span><span class="s5"> {<span class="Apple-converted-space">        </span></span><span class="s6">font-size</span><span class="s5">: </span><span class="s8">0.95em</span><span class="s5">;<span class="Apple-converted-space">        </span></span><span class="s6">padding-left</span><span class="s5">: </span><span class="s8">20px</span><span class="s5">;<span class="Apple-converted-space">      </span>}<span class="Apple-converted-space">        </span></span><span class="s4">ol</span><span class="s5"> </span><span class="s4">li</span><span class="s5"> {<span class="Apple-converted-space">        </span></span><span class="s6">margin-bottom</span><span class="s5">: </span><span class="s8">6px</span><span class="s5">;<span class="Apple-converted-space">      </span>}<span class="Apple-converted-space">        </span></span><span class="s4">a</span><span class="s5"> {<span class="Apple-converted-space">        </span></span><span class="s6">color</span><span class="s5">: </span><span class="s7">#2980b9</span><span class="s5">;<span class="Apple-converted-space">        </span></span><span class="s6">text-decoration</span><span class="s5">: </span><span class="s7">none</span><span class="s5">;<span class="Apple-converted-space">      </span>}<span class="Apple-converted-space">        </span></span><span class="s4">a:hover</span><span class="s5"> {<span class="Apple-converted-space">        </span></span><span class="s6">text-decoration</span><span class="s5">: </span><span class="s7">underline</span><span class="s5">;<span class="Apple-converted-space">      </span>}<span class="Apple-converted-space">    </span></span><span class="s1">&lt;/</span><span class="s2">style</span><span class="s1">&gt;</span><span class="s3"><span class="Apple-converted-space">  </span></span><span class="s1">&lt;/</span><span class="s2">head</span><span class="s1">&gt;&lt;</span><span class="s2">b</span><span class="s1">&gt;</span><span class="s3">Query:</span><span class="s1">&lt;/</span><span class="s2">b</span><span class="s1">&gt;</span><span class="s3"> why first few tokens matter in llm safety</span><span class="s1">&lt;</span><span class="s2">h2</span><span class="s1">&gt;</span><span class="s3">Section 1: Shallow Safety Alignment and Its Impact</span><span class="s1">&lt;/</span><span class="s2">h2</span><span class="s1">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">ul</span><span class="s9">&gt;</span><span class="s11"> </span><span class="s9">&lt;</span><span class="s10">li</span><span class="s9">&gt;</span><span class="s11"> </span><span class="s9">&lt;</span><span class="s10">b</span><span class="s9">&gt;</span><span class="s11">TL;DR:</span><span class="s9">&lt;/</span><span class="s10">b</span><span class="s9">&gt;</span><span class="s11"> Current safety measures in Large Language Models (LLMs) often result in "shallow safety alignment," where the model's decision to refuse or comply with a prompt is heavily determined by the first few tokens it generates. This occurs because alignment training often teaches models to start refusal responses with specific phrases.</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span><span class="s11"> </span><span class="s9">&lt;/</span><span class="s10">ul</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">p</span><span class="s9">&gt;</span><span class="s11">The first few tokens generated by a Large Language Model (LLM) are critical for safety due to a phenomenon known as "shallow safety alignment" [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-1"</span><span class="s9">&gt;</span><span class="s11">1</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">, </span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-3"</span><span class="s9">&gt;</span><span class="s11">3</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">]. This means that the safety training an LLM undergoes primarily adapts the model's generative distribution over only its very first few output tokens to produce a refusal response [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-1"</span><span class="s9">&gt;</span><span class="s11">1</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">, </span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-3"</span><span class="s9">&gt;</span><span class="s11">3</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">]. Consequently, if these initial tokens deviate from standard safe refusal prefixes (e.g., "I cannot," "I apologize"), the model is much more likely to generate harmful or undesirable content, even if the prompt is malicious [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-3"</span><span class="s9">&gt;</span><span class="s11">3</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">, </span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-4"</span><span class="s9">&gt;</span><span class="s11">4</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">, </span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-16"</span><span class="s9">&gt;</span><span class="s11">16</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">]. This is because the model's safety mechanisms are predominantly concentrated on this initial part of the response [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-3"</span><span class="s9">&gt;</span><span class="s11">3</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">, </span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-10"</span><span class="s9">&gt;</span><span class="s11">10</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">].</span><span class="s9">&lt;/</span><span class="s10">p</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">p</span><span class="s9">&gt;</span><span class="s11">This shallow alignment stems from the characteristics of the data used for safety training, where human labelers are more likely to begin refusal sentences at the start rather than in the middle [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-1"</span><span class="s9">&gt;</span><span class="s11">1</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">, </span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-4"</span><span class="s9">&gt;</span><span class="s11">4</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">]. As a result, LLMs learn to associate harmful queries with specific refusal tokens at the beginning of a response [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-4"</span><span class="s9">&gt;</span><span class="s11">4</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">, </span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-6"</span><span class="s9">&gt;</span><span class="s11">6</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">]. This reliance on initial tokens means that the decision to comply with or refuse a request is often made within a very limited number of generation steps [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-2"</span><span class="s9">&gt;</span><span class="s11">2</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">]. The log-perplexity (a measure of how surprising a token is) is highest on the first token and drops significantly after, indicating an increased likelihood of harmful responses once the initial few tokens are generated, if those tokens are not refusal-oriented [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-2"</span><span class="s9">&gt;</span><span class="s11">2</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">].</span><span class="s9">&lt;/</span><span class="s10">p</span><span class="s9">&gt;</span></p>
<p class="p3"><span class="s6"></span><br></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">h2</span><span class="s9">&gt;</span><span class="s11">Section 2: Vulnerabilities and Defense Strategies Related to Initial Tokens</span><span class="s9">&lt;/</span><span class="s10">h2</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">ul</span><span class="s9">&gt;</span><span class="s11"> </span><span class="s9">&lt;</span><span class="s10">li</span><span class="s9">&gt;</span><span class="s11"> </span><span class="s9">&lt;</span><span class="s10">b</span><span class="s9">&gt;</span><span class="s11">TL;DR:</span><span class="s9">&lt;/</span><span class="s10">b</span><span class="s9">&gt;</span><span class="s11"> The reliance on initial tokens for safety creates vulnerabilities, as attacks can target these first few tokens to bypass safety measures. Conversely, many defense strategies also focus on manipulating or protecting these initial tokens to ensure safe outputs.</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span><span class="s11"> </span><span class="s9">&lt;/</span><span class="s10">ul</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">p</span><span class="s9">&gt;</span><span class="s11">Shallow safety alignment makes LLMs vulnerable to various attacks that specifically target these initial tokens. For example, attacks like GCG and prefilling attacks can manipulate the LLM into generating a non-refusal prefix, leading to harmful outputs [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-1"</span><span class="s9">&gt;</span><span class="s11">1</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">, </span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-3"</span><span class="s9">&gt;</span><span class="s11">3</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">]. Fine-tuning, even with benign data, can also inadvertently disrupt safety by altering the generative distribution of these crucial initial tokens, causing the model to "forget" its safety training for refusal prefixes [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-3"</span><span class="s9">&gt;</span><span class="s11">3</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">]. Studies show that fine-tuning on samples with very short answers (which heavily impact initial token distributions) can significantly degrade an LLM's safety alignment [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-9"</span><span class="s9">&gt;</span><span class="s11">9</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">]. Once forced to generate affirmative prefixes, models often exhibit a cascading failure, where subsequent tokens increasingly favor harmful content completion [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-10"</span><span class="s9">&gt;</span><span class="s11">10</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">].</span><span class="s9">&lt;/</span><span class="s10">p</span><span class="s9">&gt;</span></p>
<p class="p4"><span class="s1">&lt;</span><span class="s2">p</span><span class="s1">&gt;</span><span class="s6">On the other hand, understanding the importance of initial tokens has also guided the development of defense mechanisms. Many strategies aim to protect or control the generation of the first few tokens [</span><span class="s1">&lt;</span><span class="s2">a</span><span class="s6"> </span><span class="s14">href</span><span class="s6">=</span><span class="s7">"#ref-1"</span><span class="s1">&gt;</span><span class="s6">1</span><span class="s1">&lt;/</span><span class="s2">a</span><span class="s1">&gt;</span><span class="s6">, </span><span class="s1">&lt;</span><span class="s2">a</span><span class="s6"> </span><span class="s14">href</span><span class="s6">=</span><span class="s7">"#ref-6"</span><span class="s1">&gt;</span><span class="s6">6</span><span class="s1">&lt;/</span><span class="s2">a</span><span class="s1">&gt;</span><span class="s6">, </span><span class="s1">&lt;</span><span class="s2">a</span><span class="s6"> </span><span class="s14">href</span><span class="s6">=</span><span class="s7">"#ref-7"</span><span class="s1">&gt;</span><span class="s6">7</span><span class="s1">&lt;/</span><span class="s2">a</span><span class="s1">&gt;</span><span class="s6">]. For instance, "safety trigger tokens" are defined as the first few generated tokens that induce a refusal response when processing malicious prompts [</span><span class="s1">&lt;</span><span class="s2">a</span><span class="s6"> </span><span class="s14">href</span><span class="s6">=</span><span class="s7">"#ref-1"</span><span class="s1">&gt;</span><span class="s6">1</span><span class="s1">&lt;/</span><span class="s2">a</span><span class="s1">&gt;</span><span class="s6">]. Defense algorithms like D-STT identify these safety trigger tokens (often a single token) and explicitly decode them as a prefix to the response, thereby activating the model's learned safety patterns with minimal intervention [</span><span class="s1">&lt;</span><span class="s2">a</span><span class="s6"> </span><span class="s14">href</span><span class="s6">=</span><span class="s7">"#ref-1"</span><span class="s1">&gt;</span><span class="s6">1</span><span class="s1">&lt;/</span><span class="s2">a</span><span class="s1">&gt;</span><span class="s6">]. Other methods adjust the probability distribution of tokens during the initial decoding steps to steer the response towards safety [</span><span class="s1">&lt;</span><span class="s2">a</span><span class="s6"> </span><span class="s14">href</span><span class="s6">=</span><span class="s7">"#ref-6"</span><span class="s1">&gt;</span><span class="s6">6</span><span class="s1">&lt;/</span><span class="s2">a</span><span class="s1">&gt;</span><span class="s6">] or use classifiers to ensure the safety of each token generated, starting from the very first one [</span><span class="s1">&lt;</span><span class="s2">a</span><span class="s6"> </span><span class="s14">href</span><span class="s6">=</span><span class="s7">"#ref-13"</span><span class="s1">&gt;</span><span class="s6">13</span><span class="s1">&lt;/</span><span class="s2">a</span><span class="s1">&gt;</span><span class="s6">]. These approaches acknowledge that identifying unsafe output can often occur within the early stages of generation, such as the initial 25% of the content [</span><span class="s1">&lt;</span><span class="s2">a</span><span class="s6"> </span><span class="s14">href</span><span class="s6">=</span><span class="s7">"#ref-12"</span><span class="s1">&gt;</span><span class="s6">12</span><span class="s1">&lt;/</span><span class="s2">a</span><span class="s1">&gt;</span><span class="s6">].</span><span class="s1">&lt;/</span><span class="s2">p</span><span class="s1">&gt;</span></p>
<p class="p3"><span class="s6"></span><br></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">h2</span><span class="s9">&gt;</span><span class="s11">Section 3: Deeper Mechanisms and Broader Implications</span><span class="s9">&lt;/</span><span class="s10">h2</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">ul</span><span class="s9">&gt;</span><span class="s11"> </span><span class="s9">&lt;</span><span class="s10">li</span><span class="s9">&gt;</span><span class="s11"> </span><span class="s9">&lt;</span><span class="s10">b</span><span class="s9">&gt;</span><span class="s11">TL;DR:</span><span class="s9">&lt;/</span><span class="s10">b</span><span class="s9">&gt;</span><span class="s11"> The focus on initial tokens is linked to how LLMs process information, with early layers discriminating harmfulness and alignment associating these assessments with initial refusal tokens. This highlights the need for safety measures that persist beyond the first few tokens.</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span><span class="s11"> </span><span class="s9">&lt;/</span><span class="s10">ul</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">p</span><span class="s9">&gt;</span><span class="s11">The significance of the first few tokens is tied to the internal workings of LLMs. Research suggests that LLMs can identify malicious inputs in their early layers based on ethical concepts learned during pre-training [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-14"</span><span class="s9">&gt;</span><span class="s11">14</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">, </span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-19"</span><span class="s9">&gt;</span><span class="s11">19</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">]. Safety alignment then works by associating these early-layer assessments with "shallow guess tokens" (representing positive or negative emotions) in the middle layers, which are subsequently refined into specific affirmative or refusal initial response tokens [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-14"</span><span class="s9">&gt;</span><span class="s11">14</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">]. Jailbreak attacks often succeed by disturbing this association in the middle layers, preventing the transformation of an unethical classification into a refusal [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-14"</span><span class="s9">&gt;</span><span class="s11">14</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">, </span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-21"</span><span class="s9">&gt;</span><span class="s11">21</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">]. The initial tokens effectively set the tone for the entire response [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-6"</span><span class="s9">&gt;</span><span class="s11">6</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">], and their distribution is heavily influenced by alignment tuning compared to later tokens [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-5"</span><span class="s9">&gt;</span><span class="s11">5</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">, </span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-18"</span><span class="s9">&gt;</span><span class="s11">18</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">].</span><span class="s9">&lt;/</span><span class="s10">p</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">p</span><span class="s9">&gt;</span><span class="s11">This heavy reliance on initial tokens for safety implies that current alignment methods may not be consistently applied throughout longer sequences, with the effect of alignment diminishing for later tokens [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-11"</span><span class="s9">&gt;</span><span class="s11">11</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">, </span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-17"</span><span class="s9">&gt;</span><span class="s11">17</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">, </span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-18"</span><span class="s9">&gt;</span><span class="s11">18</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">]. This can lead to situations where a model might start with a refusal but could still be steered towards generating harmful content later in the response if the initial safety signal is not robust enough or if attacks target deeper parts of the generation [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-1"</span><span class="s9">&gt;</span><span class="s11">1</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">, </span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-8"</span><span class="s9">&gt;</span><span class="s11">8</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">]. Therefore, there's a growing recognition that future safety alignment needs to be "more than just a few tokens deep," aiming for a "deep safety alignment" where models can recover from harmful starting conditions or maintain safety awareness throughout the entire generation process [</span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-3"</span><span class="s9">&gt;</span><span class="s11">3</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">, </span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-10"</span><span class="s9">&gt;</span><span class="s11">10</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">, </span><span class="s9">&lt;</span><span class="s10">a</span><span class="s11"> </span><span class="s12">href</span><span class="s11">=</span><span class="s13">"#ref-17"</span><span class="s9">&gt;</span><span class="s11">17</span><span class="s9">&lt;/</span><span class="s10">a</span><span class="s9">&gt;</span><span class="s11">].</span><span class="s9">&lt;/</span><span class="s10">p</span><span class="s9">&gt;</span></p>
<p class="p3"><span class="s6"></span><br></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">h3</span><span class="s9">&gt;</span><span class="s11">References</span><span class="s9">&lt;/</span><span class="s10">h3</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">ol</span><span class="s9">&gt;&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-1"</span><span class="s9">&gt;</span><span class="s11">One Trigger Token Is Enough: A Defense Strategy for Balancing Safety and Usability in Large Language Models (Gu et. al., 2025)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-2"</span><span class="s9">&gt;</span><span class="s11">Align in Depth: Defending Jailbreak Attacks via Progressive Answer Detoxification (Zhang et. al., 2025)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-3"</span><span class="s9">&gt;</span><span class="s11">Safety Alignment Should Be Made More Than Just a Few Tokens Deep (Qi et. al., 2024)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-4"</span><span class="s9">&gt;</span><span class="s11">Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training (Yuan et. al., 2024)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-5"</span><span class="s9">&gt;</span><span class="s11">Improving LLM Safety Alignment with Dual-Objective Optimization (Zhao et. al., 2025)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-6"</span><span class="s9">&gt;</span><span class="s11">LightDefense: A Lightweight Uncertainty-Driven Defense against Jailbreaks via Shifted Token Distribution (Yang et. al., 2025)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-7"</span><span class="s9">&gt;</span><span class="s11">MoGU: A Framework for Enhancing Safety of Open-Sourced LLMs While Preserving Their Usability (Du et. al., 2024)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-8"</span><span class="s9">&gt;</span><span class="s11">Probing the Safety Response Boundary of Large Language Models via Unsafe Decoding Path Generation (Wang et. al., 2024)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-9"</span><span class="s9">&gt;</span><span class="s11">Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety (Guan et. al., 2025)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-10"</span><span class="s9">&gt;</span><span class="s11">Output Constraints as Attack Surface: Exploiting Structured Generation to Bypass LLM Safety Mechanisms (Zhang et. al., 2025)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-11"</span><span class="s9">&gt;</span><span class="s11">LookAhead Tuning: Safer Language Models via Partial Answer Previews (Liu et. al., 2025)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-12"</span><span class="s9">&gt;</span><span class="s11">Online Safety Analysis for LLMs: a Benchmark, an Assessment, and a Path Forward (Xie et. al., 2024)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-13"</span><span class="s9">&gt;</span><span class="s11">Root Defence Strategies: Ensuring Safety of LLM at the Decoding Level (Zeng et. al., 2024)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-14"</span><span class="s9">&gt;</span><span class="s11">How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States (Zhou et. al., 2024)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-15"</span><span class="s9">&gt;</span><span class="s11">Multilingual Blending: LLM Safety Alignment Evaluation with Language Mixture (Song et. al., 2024)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-16"</span><span class="s9">&gt;</span><span class="s11">AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs (Liao et. al., 2024)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-17"</span><span class="s9">&gt;</span><span class="s11">Weak-to-Strong Jailbreaking on Large Language Models (Zhao et. al., 2024)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-18"</span><span class="s9">&gt;</span><span class="s11">The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context Learning (Lin et. al., 2023)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-19"</span><span class="s9">&gt;</span><span class="s11">Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing (Zhao et. al., 2024)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-20"</span><span class="s9">&gt;</span><span class="s11">Locking Down the Finetuned LLMs Safety (Zhu et. al., 2024)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-21"</span><span class="s9">&gt;</span><span class="s11">Quantized Delta Weight Is Safety Keeper (Liu et. al., 2024)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-22"</span><span class="s9">&gt;</span><span class="s11">KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization (Hooper et. al., 2024)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;</span></p>
<p class="p2"><span class="s9">&lt;</span><span class="s10">li</span><span class="s11"> </span><span class="s12">id</span><span class="s11">=</span><span class="s13">"ref-23"</span><span class="s9">&gt;</span><span class="s11">SaRO: Enhancing LLM Safety through Reasoning-based Alignment (Mou et. al., 2025)</span><span class="s9">&lt;/</span><span class="s10">li</span><span class="s9">&gt;&lt;/</span><span class="s10">ol</span><span class="s9">&gt;</span></p>
</body>
</html>
